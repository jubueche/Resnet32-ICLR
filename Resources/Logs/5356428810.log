Sender: LSF System <lsfadmin@zhcc004>
Subject: Job 779958: <python3 trainer_resnet.py -seed=0 -batch_size=512 -weight_decay=0.0005 -momentum=0.9 -save_every=10 -lr=0.1 -n_attack_steps=10 -beta_robustness=0.0 -gamma=0.0 -eps_pga=0.0 -eta_train=0.11 -eta_mode=ind -clipping_alpha=2.0 -attack_size_mismatch=0.2 -initial_std=0.001 -pretrained -burn_in=0 -workers=4 -n_epochs=300 -dataset=cifar10 -architecture=resnet9 -start_epoch=60 -data_dir=/dataP/jbu -session_id=5356428810> in cluster <ZHC2clusterLSF> Exited

Job <python3 trainer_resnet.py -seed=0 -batch_size=512 -weight_decay=0.0005 -momentum=0.9 -save_every=10 -lr=0.1 -n_attack_steps=10 -beta_robustness=0.0 -gamma=0.0 -eps_pga=0.0 -eta_train=0.11 -eta_mode=ind -clipping_alpha=2.0 -attack_size_mismatch=0.2 -initial_std=0.001 -pretrained -burn_in=0 -workers=4 -n_epochs=300 -dataset=cifar10 -architecture=resnet9 -start_epoch=60 -data_dir=/dataP/jbu -session_id=5356428810> was submitted from host <zhcc022> by user <jbu> in cluster <ZHC2clusterLSF> at Thu Dec  2 10:50:00 2021
Job was executed on host(s) <zhcc004>, in queue <prod.med>, as user <jbu> in cluster <ZHC2clusterLSF> at Thu Dec  2 10:50:01 2021
</u/jbu> was used as the home directory.
</u/jbu/Master-Thesis> was used as the working directory.
Started at Thu Dec  2 10:50:01 2021
Terminated at Thu Dec  2 10:50:14 2021
Results reported at Thu Dec  2 10:50:14 2021

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python3 trainer_resnet.py -seed=0 -batch_size=512 -weight_decay=0.0005 -momentum=0.9 -save_every=10 -lr=0.1 -n_attack_steps=10 -beta_robustness=0.0 -gamma=0.0 -eps_pga=0.0 -eta_train=0.11 -eta_mode=ind -clipping_alpha=2.0 -attack_size_mismatch=0.2 -initial_std=0.001 -pretrained -burn_in=0 -workers=4 -n_epochs=300 -dataset=cifar10 -architecture=resnet9 -start_epoch=60 -data_dir=/dataP/jbu -session_id=5356428810
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   21.76 sec.
    Max Memory :                                 1937 MB
    Average Memory :                             1416.25 MB
    Total Requested Memory :                     -
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              7
    Max Threads :                                131
    Run time :                                   14 sec.
    Turnaround time :                            14 sec.

The output (if any) follows:

Loaded pretrained model from /ibm/gpfs-homes/jbu/Master-Thesis/Resources/cifar10_pretrained_models/resnet9.th
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
/u/jbu/.conda/envs/msc/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
 * Prec@1 87.640
 * Prec@1 19.240
Traceback (most recent call last):
  File "/u/jbu/.conda/envs/msc/lib/python3.7/threading.py", line 300, in wait
    gotit = waiter.acquire(True, timeout)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/u/jbu/.conda/envs/msc/lib/python3.7/queue.py", line 179, in get
    self.not_empty.wait(remaining)
  File "/u/jbu/.conda/envs/msc/lib/python3.7/threading.py", line 300, in wait
    gotit = waiter.acquire(True, timeout)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "trainer_resnet.py", line 334, in <module>
    main()
  File "trainer_resnet.py", line 139, in main
    mean_prec1, std_prec1 = validate_noisy(val_loader, model, args, eta_inf=args.eta_train, eta_mode=args.eta_mode, n_inf=3)
  File "trainer_resnet.py", line 256, in validate_noisy
    accs[i] = validate(val_loader, model_noisy, args)
  File "trainer_resnet.py", line 273, in validate
    for i, (input, target) in enumerate(val_loader):
  File "/u/jbu/.conda/envs/msc/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 435, in __next__
    data = self._next_data()
  File "/u/jbu/.conda/envs/msc/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1068, in _next_data
    idx, data = self._get_data()
  File "/u/jbu/.conda/envs/msc/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1024, in _get_data
    success, data = self._try_get_data()
  File "/u/jbu/.conda/envs/msc/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 872, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/u/jbu/.conda/envs/msc/lib/python3.7/queue.py", line 182, in get
    return item
  File "/u/jbu/.conda/envs/msc/lib/python3.7/threading.py", line 244, in __exit__
    return self._lock.__exit__(*args)
RuntimeError: release unlocked lock
