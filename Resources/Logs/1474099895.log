Sender: LSF System <lsfadmin@zhcc008>
Subject: Job 768128: <python3 trainer_resnet.py -seed=0 -batch_size=256 -weight_decay=0.0005 -momentum=0.9 -save_every=10 -lr=0.1 -n_attack_steps=3 -beta_robustness=0.1 -eta_train=0.056 -eta_mode=range -clipping_alpha=2.0 -attack_size_mismatch=0.2 -initial_std=0.001 -pretrained -burn_in=0 -workers=4 -n_epochs=300 -dataset=cifar10 -architecture=resnet32 -start_epoch=60 -data_dir=/dataP/jbu -session_id=1474099895> in cluster <ZHC2clusterLSF> Exited

Job <python3 trainer_resnet.py -seed=0 -batch_size=256 -weight_decay=0.0005 -momentum=0.9 -save_every=10 -lr=0.1 -n_attack_steps=3 -beta_robustness=0.1 -eta_train=0.056 -eta_mode=range -clipping_alpha=2.0 -attack_size_mismatch=0.2 -initial_std=0.001 -pretrained -burn_in=0 -workers=4 -n_epochs=300 -dataset=cifar10 -architecture=resnet32 -start_epoch=60 -data_dir=/dataP/jbu -session_id=1474099895> was submitted from host <zhcc022> by user <jbu> in cluster <ZHC2clusterLSF> at Tue Nov  2 14:07:40 2021
Job was executed on host(s) <zhcc008>, in queue <prod.med>, as user <jbu> in cluster <ZHC2clusterLSF> at Tue Nov  2 14:07:41 2021
</u/jbu> was used as the home directory.
</u/jbu/Master-Thesis> was used as the working directory.
Started at Tue Nov  2 14:07:41 2021
Terminated at Tue Nov  2 14:08:41 2021
Results reported at Tue Nov  2 14:08:41 2021

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python3 trainer_resnet.py -seed=0 -batch_size=256 -weight_decay=0.0005 -momentum=0.9 -save_every=10 -lr=0.1 -n_attack_steps=3 -beta_robustness=0.1 -eta_train=0.056 -eta_mode=range -clipping_alpha=2.0 -attack_size_mismatch=0.2 -initial_std=0.001 -pretrained -burn_in=0 -workers=4 -n_epochs=300 -dataset=cifar10 -architecture=resnet32 -start_epoch=60 -data_dir=/dataP/jbu -session_id=1474099895
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   92.47 sec.
    Max Memory :                                 2015 MB
    Average Memory :                             1784.91 MB
    Total Requested Memory :                     -
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              7
    Max Threads :                                24
    Run time :                                   60 sec.
    Turnaround time :                            61 sec.

The output (if any) follows:

Loaded pretrained model from /ibm/gpfs-homes/jbu/Master-Thesis/Resources/cifar10_pretrained_models/resnet32.th
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
/u/jbu/.conda/envs/msc/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
 * Prec@1 93.900
 * Prec@1 19.920
 * Prec@1 20.820
 * Prec@1 17.200
 * Prec@1 20.100
 * Noisy Prec@1 19.37
After loading, with clipping@2.00 19.92 w/o 93.90 noisy: 19.37pm1.92
current lr 2.00000e-02
Epoch: [60][0/176]	Time 0.992 (0.992)	Data 0.488 (0.488)	Loss 1.6332 (1.6332)	Prec@1 82.422 (82.422)
Epoch: [60][17/176]	Time 0.461 (0.492)	Data 0.001 (0.028)	Loss 1.3194 (1.4524)	Prec@1 88.672 (89.800)
Epoch: [60][34/176]	Time 0.461 (0.477)	Data 0.001 (0.015)	Loss 1.1752 (1.3905)	Prec@1 87.500 (88.650)
Epoch: [60][51/176]	Time 0.461 (0.472)	Data 0.001 (0.011)	Loss 1.0207 (1.3075)	Prec@1 88.672 (88.477)
Epoch: [60][68/176]	Time 0.463 (0.469)	Data 0.001 (0.008)	Loss 0.9798 (1.2404)	Prec@1 89.844 (88.779)
Epoch: [60][85/176]	Time 0.459 (0.468)	Data 0.001 (0.007)	Loss 0.9815 (1.1881)	Prec@1 89.062 (89.167)
Traceback (most recent call last):
  File "trainer_resnet.py", line 339, in <module>
    main()
  File "trainer_resnet.py", line 144, in main
    train(train_loader, model, criterion, optimizer, epoch, args=args, clip_fn=clip_weights)
  File "trainer_resnet.py", line 219, in train
    epoch=epoch - args.start_epoch
  File "/ibm/gpfs-homes/jbu/Master-Thesis/Losses/torch_loss.py", line 138, in compute_gradient_and_backward
    X
  File "/ibm/gpfs-homes/jbu/Master-Thesis/Losses/torch_loss.py", line 77, in _adversarial_loss
    output_theta_star = self.model_theta_star(X)
  File "/u/jbu/.conda/envs/msc/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/u/jbu/.conda/envs/msc/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py", line 159, in forward
    return self.module(*inputs[0], **kwargs[0])
  File "/u/jbu/.conda/envs/msc/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/ibm/gpfs-homes/jbu/Master-Thesis/Architectures/cifar_resnet.py", line 108, in forward
    out = F.relu(self.bn1(self.conv1(x)))
  File "/u/jbu/.conda/envs/msc/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/u/jbu/.conda/envs/msc/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py", line 111, in forward
    self.num_batches_tracked = self.num_batches_tracked + 1
KeyboardInterrupt
