Sender: LSF System <lsfadmin@zhcc004>
Subject: Job 777566: <python3 trainer_resnet.py -seed=1 -batch_size=256 -weight_decay=0.0005 -momentum=0.9 -save_every=10 -lr=0.1 -n_attack_steps=3 -beta_robustness=0.0 -gamma=0.1 -eps_pga=0.0 -eta_train=0.0 -inner_lr=0.1 -eta_mode=ind -clipping_alpha=2.0 -attack_size_mismatch=0.01 -initial_std=0.001 -pretrained -burn_in=0 -workers=4 -n_epochs=300 -dataset=cifar10 -architecture=resnet32 -start_epoch=60 -data_dir=/dataP/jbu -session_id=6840900006> in cluster <ZHC2clusterLSF> Exited

Job <python3 trainer_resnet.py -seed=1 -batch_size=256 -weight_decay=0.0005 -momentum=0.9 -save_every=10 -lr=0.1 -n_attack_steps=3 -beta_robustness=0.0 -gamma=0.1 -eps_pga=0.0 -eta_train=0.0 -inner_lr=0.1 -eta_mode=ind -clipping_alpha=2.0 -attack_size_mismatch=0.01 -initial_std=0.001 -pretrained -burn_in=0 -workers=4 -n_epochs=300 -dataset=cifar10 -architecture=resnet32 -start_epoch=60 -data_dir=/dataP/jbu -session_id=6840900006> was submitted from host <zhcc022> by user <jbu> in cluster <ZHC2clusterLSF> at Wed Nov 24 14:40:33 2021
Job was executed on host(s) <zhcc004>, in queue <prod.med>, as user <jbu> in cluster <ZHC2clusterLSF> at Wed Nov 24 14:40:34 2021
</u/jbu> was used as the home directory.
</u/jbu/Resnet32-ICLR> was used as the working directory.
Started at Wed Nov 24 14:40:34 2021
Terminated at Wed Nov 24 14:40:54 2021
Results reported at Wed Nov 24 14:40:54 2021

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python3 trainer_resnet.py -seed=1 -batch_size=256 -weight_decay=0.0005 -momentum=0.9 -save_every=10 -lr=0.1 -n_attack_steps=3 -beta_robustness=0.0 -gamma=0.1 -eps_pga=0.0 -eta_train=0.0 -inner_lr=0.1 -eta_mode=ind -clipping_alpha=2.0 -attack_size_mismatch=0.01 -initial_std=0.001 -pretrained -burn_in=0 -workers=4 -n_epochs=300 -dataset=cifar10 -architecture=resnet32 -start_epoch=60 -data_dir=/dataP/jbu -session_id=6840900006
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   43.24 sec.
    Max Memory :                                 2038 MB
    Average Memory :                             1591.20 MB
    Total Requested Memory :                     -
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              7
    Max Threads :                                131
    Run time :                                   21 sec.
    Turnaround time :                            21 sec.

The output (if any) follows:

Loaded pretrained model from /ibm/gpfs-homes/jbu/Resnet32-ICLR/Resources/cifar10_pretrained_models/resnet32.th
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
/u/jbu/.conda/envs/msc/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
 * Prec@1 99.440
 * Prec@1 14.440
 * Prec@1 14.440
 * Prec@1 14.440
 * Prec@1 14.440
 * Noisy Prec@1 14.44
After loading, with clipping@2.00 14.44 w/o 99.44 noisy: 14.44pm0.00
current lr 2.00000e-02
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x1002857e34d0>
Traceback (most recent call last):
  File "/u/jbu/.conda/envs/msc/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1202, in __del__
    def __del__(self):
KeyboardInterrupt
Epoch: [60][0/176]	Time 0.914 (0.914)	Data 0.496 (0.496)	Loss 0.9999 (0.9999)	Prec@1 89.844 (89.844)
Traceback (most recent call last):
  File "trainer_resnet.py", line 344, in <module>
    main()
  File "trainer_resnet.py", line 149, in main
    train(train_loader, model, criterion, optimizer, epoch, args=args, clip_fn=clip_weights)
  File "trainer_resnet.py", line 224, in train
    epoch=epoch - args.start_epoch
  File "/ibm/gpfs-homes/jbu/Resnet32-ICLR/Losses/torch_loss.py", line 275, in compute_gradient_and_backward
    y
  File "/ibm/gpfs-homes/jbu/Resnet32-ICLR/Losses/torch_loss.py", line 244, in _adversarial_loss
    theta_star[name] = self.model_theta.state_dict()[name] + self.gamma * (theta_star[name] - self.model_theta.state_dict()[name])
  File "/u/jbu/.conda/envs/msc/lib/python3.7/site-packages/torch/nn/modules/module.py", line 907, in state_dict
    module.state_dict(destination, prefix + name + '.', keep_vars=keep_vars)
  File "/u/jbu/.conda/envs/msc/lib/python3.7/site-packages/torch/nn/modules/module.py", line 907, in state_dict
    module.state_dict(destination, prefix + name + '.', keep_vars=keep_vars)
  File "/u/jbu/.conda/envs/msc/lib/python3.7/site-packages/torch/nn/modules/module.py", line 907, in state_dict
    module.state_dict(destination, prefix + name + '.', keep_vars=keep_vars)
  [Previous line repeated 1 more time]
  File "/u/jbu/.conda/envs/msc/lib/python3.7/site-packages/torch/nn/modules/module.py", line 904, in state_dict
    self._save_to_state_dict(destination, prefix, keep_vars)
  File "/u/jbu/.conda/envs/msc/lib/python3.7/site-packages/torch/nn/modules/module.py", line 868, in _save_to_state_dict
    destination[prefix + name] = buf if keep_vars else buf.detach()
KeyboardInterrupt
