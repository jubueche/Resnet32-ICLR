Sender: LSF System <lsfadmin@zhcc003>
Subject: Job 777155: <python3 trainer_resnet.py -seed=0 -batch_size=256 -weight_decay=0.0005 -momentum=0.9 -save_every=10 -lr=0.1 -n_attack_steps=3 -beta_robustness=0.0 -gamma=0.1 -eps_pga=0.001 -eta_train=0.0 -eta_mode=ind -clipping_alpha=2.0 -attack_size_mismatch=0.2 -initial_std=0.001 -pretrained -burn_in=0 -workers=4 -n_epochs=300 -dataset=cifar10 -architecture=resnet32 -start_epoch=60 -data_dir=/dataP/jbu -session_id=4155615203> in cluster <ZHC2clusterLSF> Exited

Job <python3 trainer_resnet.py -seed=0 -batch_size=256 -weight_decay=0.0005 -momentum=0.9 -save_every=10 -lr=0.1 -n_attack_steps=3 -beta_robustness=0.0 -gamma=0.1 -eps_pga=0.001 -eta_train=0.0 -eta_mode=ind -clipping_alpha=2.0 -attack_size_mismatch=0.2 -initial_std=0.001 -pretrained -burn_in=0 -workers=4 -n_epochs=300 -dataset=cifar10 -architecture=resnet32 -start_epoch=60 -data_dir=/dataP/jbu -session_id=4155615203> was submitted from host <zhcc022> by user <jbu> in cluster <ZHC2clusterLSF> at Tue Nov 23 12:49:11 2021
Job was executed on host(s) <zhcc003>, in queue <prod.med>, as user <jbu> in cluster <ZHC2clusterLSF> at Tue Nov 23 12:49:12 2021
</u/jbu> was used as the home directory.
</u/jbu/Resnet32-ICLR> was used as the working directory.
Started at Tue Nov 23 12:49:12 2021
Terminated at Tue Nov 23 12:50:30 2021
Results reported at Tue Nov 23 12:50:30 2021

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python3 trainer_resnet.py -seed=0 -batch_size=256 -weight_decay=0.0005 -momentum=0.9 -save_every=10 -lr=0.1 -n_attack_steps=3 -beta_robustness=0.0 -gamma=0.1 -eps_pga=0.001 -eta_train=0.0 -eta_mode=ind -clipping_alpha=2.0 -attack_size_mismatch=0.2 -initial_std=0.001 -pretrained -burn_in=0 -workers=4 -n_epochs=300 -dataset=cifar10 -architecture=resnet32 -start_epoch=60 -data_dir=/dataP/jbu -session_id=4155615203
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   101.67 sec.
    Max Memory :                                 2012 MB
    Average Memory :                             1326.00 MB
    Total Requested Memory :                     -
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              7
    Max Threads :                                133
    Run time :                                   77 sec.
    Turnaround time :                            79 sec.

The output (if any) follows:

Loaded pretrained model from /ibm/gpfs-homes/jbu/Resnet32-ICLR/Resources/cifar10_pretrained_models/resnet32.th
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
/u/jbu/.conda/envs/msc/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
 * Prec@1 94.280
 * Prec@1 15.320
 * Prec@1 15.320
 * Prec@1 15.320
 * Prec@1 15.320
 * Noisy Prec@1 15.32
After loading, with clipping@2.00 15.32 w/o 94.28 noisy: 15.32pm0.00
current lr 2.00000e-02
Epoch: [60][0/176]	Time 1.278 (1.278)	Data 0.570 (0.570)	Loss 1.8791 (1.8791)	Prec@1 87.891 (87.891)
Epoch: [60][17/176]	Time 0.531 (0.602)	Data 0.001 (0.033)	Loss 0.9853 (1.5158)	Prec@1 86.328 (85.438)
Epoch: [60][34/176]	Time 0.653 (0.585)	Data 0.002 (0.018)	Loss 0.9294 (1.2889)	Prec@1 83.594 (84.397)
Epoch: [60][51/176]	Time 0.697 (0.583)	Data 0.001 (0.012)	Loss 0.8544 (1.1587)	Prec@1 88.281 (85.021)
Epoch: [60][68/176]	Time 0.532 (0.580)	Data 0.001 (0.010)	Loss 0.7301 (1.0715)	Prec@1 89.844 (85.921)
Epoch: [60][85/176]	Time 0.540 (0.579)	Data 0.001 (0.008)	Loss 0.7996 (1.0206)	Prec@1 89.453 (86.560)
Traceback (most recent call last):
  File "trainer_resnet.py", line 222, in train
    output = model(input_var) #! This is inefficient, right?
  File "/u/jbu/.conda/envs/msc/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/u/jbu/.conda/envs/msc/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py", line 151, in forward
    for t in chain(self.module.parameters(), self.module.buffers()):
  File "/u/jbu/.conda/envs/msc/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1137, in buffers
    for name, buf in self.named_buffers(recurse=recurse):
  File "/u/jbu/.conda/envs/msc/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1163, in named_buffers
    for elem in gen:
  File "/u/jbu/.conda/envs/msc/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1062, in _named_members
    if v is None or v in memo:
  File "/u/jbu/.conda/envs/msc/lib/python3.7/site-packages/torch/tensor.py", line 598, in __hash__
    from torch.overrides import has_torch_function, handle_torch_function
  File "<frozen importlib._bootstrap>", line 1009, in _handle_fromlist
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "trainer_resnet.py", line 333, in <module>
    main()
  File "trainer_resnet.py", line 138, in main
    train(train_loader, model, criterion, optimizer, epoch, args=args, clip_fn=clip_weights)
  File "trainer_resnet.py", line 222, in train
    output = model(input_var) #! This is inefficient, right?
KeyboardInterrupt
